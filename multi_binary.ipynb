{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX6jz6Rcb4ze",
        "outputId": "e8a73010-8a4a-41e0-d91c-1e14b5e65290"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S60KIZ9jbzKa",
        "outputId": "14866ed6-68ed-4859-f8dc-bfecec52c6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/PHOTOCL.zip\n",
            "replace /content/PHOTOCL/dataset_original/Painting/painting_00001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/PHOTOCL.zip -d /content/PHOTOCL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm albumentations --quiet\n"
      ],
      "metadata": {
        "id": "HCak-U1gcJeW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import timm\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n"
      ],
      "metadata": {
        "id": "9xRXIpc4c1M4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"/content/PHOTOCL/dataset_original\"\n",
        "CLASSES = [\"Photo\", \"Painting\", \"Schematics\", \"Sketch\", \"Text\"]\n",
        "\n",
        "samples = []\n",
        "for cls in CLASSES:\n",
        "    folder = os.path.join(DATA_ROOT, cls)\n",
        "    for fname in os.listdir(folder):\n",
        "        samples.append((os.path.join(folder, fname), cls))\n",
        "\n",
        "random.shuffle(samples)\n"
      ],
      "metadata": {
        "id": "v98M7nwGc2il"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(0.8 * len(samples))\n",
        "train_samples = samples[:split]\n",
        "val_samples = samples[split:]\n"
      ],
      "metadata": {
        "id": "7l-NH2aLdKJU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PhotoCLMultiTaskDataset(Dataset):\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "\n",
        "        image = cv2.imread(path)\n",
        "\n",
        "        if image is None:\n",
        "            new_idx = random.randint(0, len(self.samples) - 1)\n",
        "            return self.__getitem__(new_idx)\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        target = {\n",
        "            \"is_photo\": torch.tensor([label == \"Photo\"], dtype=torch.float32),\n",
        "            \"is_text\": torch.tensor([label == \"Text\"], dtype=torch.float32),\n",
        "            \"is_art\": torch.tensor([label in [\"Painting\", \"Sketch\"]], dtype=torch.float32),\n",
        "            \"is_schema\": torch.tensor([label == \"Schematics\"], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, target\n"
      ],
      "metadata": {
        "id": "pTKrPAL6dM2U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tfms = A.Compose([\n",
        "    A.Resize(300, 300),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.GaussianBlur(p=0.2),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_tfms = A.Compose([\n",
        "    A.Resize(300, 300),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n"
      ],
      "metadata": {
        "id": "3CP2LWuydPax"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = PhotoCLMultiTaskDataset(train_samples, train_tfms)\n",
        "val_ds = PhotoCLMultiTaskDataset(val_samples, val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "RdXHz-WBdSGc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskVisionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            \"efficientnet_b3\",\n",
        "            pretrained=True,\n",
        "            num_classes=0\n",
        "        )\n",
        "        feat_dim = self.backbone.num_features\n",
        "\n",
        "        self.heads = nn.ModuleDict({\n",
        "            \"is_photo\": nn.Linear(feat_dim, 1),\n",
        "            \"is_text\": nn.Linear(feat_dim, 1),\n",
        "            \"is_art\": nn.Linear(feat_dim, 1),\n",
        "            \"is_schema\": nn.Linear(feat_dim, 1),\n",
        "        })\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        return {k: torch.sigmoid(h(feats)) for k, h in self.heads.items()}\n"
      ],
      "metadata": {
        "id": "RpNf4SyudUql"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = {\n",
        "    \"is_photo\": 1.0,\n",
        "    \"is_text\": 1.0,\n",
        "    \"is_art\": 0.8,\n",
        "    \"is_schema\": 0.8,\n",
        "}\n",
        "\n",
        "def multitask_loss(preds, targets):\n",
        "    loss = 0\n",
        "    for k in preds:\n",
        "        loss += weights[k] * nn.functional.binary_cross_entropy(\n",
        "            preds[k], targets[k].to(preds[k].device)\n",
        "        )\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "XKpk3E26dYF9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = MultiTaskVisionModel().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
        "\n",
        "EPOCHS = 5\n"
      ],
      "metadata": {
        "id": "QOVUi5S2dbIL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(loader, train=True):\n",
        "    model.train() if train else model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    all_preds = {k: [] for k in weights}\n",
        "    all_targets = {k: [] for k in weights}\n",
        "\n",
        "    for images, targets in tqdm(loader):\n",
        "        images = images.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = multitask_loss(outputs, targets)\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        for k in outputs:\n",
        "            all_preds[k].append(outputs[k].detach().cpu().numpy())\n",
        "            all_targets[k].append(targets[k].numpy())\n",
        "\n",
        "    metrics = {}\n",
        "    for k in weights:\n",
        "        y_true = np.concatenate(all_targets[k])\n",
        "        y_pred = np.concatenate(all_preds[k])\n",
        "        metrics[k] = {\n",
        "            \"F1\": f1_score(y_true > 0.5, y_pred > 0.5),\n",
        "            \"AUC\": roc_auc_score(y_true, y_pred)\n",
        "        }\n",
        "\n",
        "    return total_loss / len(loader), metrics\n"
      ],
      "metadata": {
        "id": "Aus80-Gqde0l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_image(path):\n",
        "    try:\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            return False\n",
        "        _ = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "beEYmikAgQDR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_samples = []\n",
        "bad_samples = []\n",
        "\n",
        "for path, label in samples:\n",
        "    if is_valid_image(path):\n",
        "        clean_samples.append((path, label))\n",
        "    else:\n",
        "        bad_samples.append(path)\n",
        "\n",
        "print(f\"Valid images: {len(clean_samples)}\")\n",
        "print(f\"Corrupted images removed: {len(bad_samples)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXGeP46dgTt3",
        "outputId": "28c9fdd2-4a7b-4822-bbc8-c049d45388ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid images: 41399\n",
            "Corrupted images removed: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(clean_samples)\n",
        "\n",
        "split = int(0.8 * len(clean_samples))\n",
        "train_samples = clean_samples[:split]\n",
        "val_samples = clean_samples[split:]\n"
      ],
      "metadata": {
        "id": "JoGriBH5gl84"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, _ = run_epoch(train_loader, train=True)\n",
        "    val_loss, val_metrics = run_epoch(val_loader, train=False)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    print(f\"Train loss: {train_loss:.4f}\")\n",
        "    print(f\"Val loss: {val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"val_loss\": val_loss,\n",
        "            },\n",
        "            \"/content/drive/MyDrive/best_multitask_model.pth\"\n",
        "        )\n",
        "        print(\"✅ Best model saved\")\n",
        "    else:\n",
        "        print(\"⚠️ Val loss worse than best\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbNOWrNddiPA",
        "outputId": "9e33732e-189d-4ab4-879c-e430ba7367ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2070/2070 [11:10<00:00,  3.09it/s]\n",
            "100%|██████████| 518/518 [01:20<00:00,  6.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Train loss: 0.1953\n",
            "Val loss: 0.0586\n",
            "✅ Best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2070/2070 [11:08<00:00,  3.10it/s]\n",
            "100%|██████████| 518/518 [01:19<00:00,  6.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/5\n",
            "Train loss: 0.0977\n",
            "Val loss: 0.0543\n",
            "✅ Best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2070/2070 [11:07<00:00,  3.10it/s]\n",
            "100%|██████████| 518/518 [01:18<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/5\n",
            "Train loss: 0.0757\n",
            "Val loss: 0.0603\n",
            "⚠️ Val loss worse than best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2070/2070 [11:08<00:00,  3.10it/s]\n",
            "100%|██████████| 518/518 [01:19<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/5\n",
            "Train loss: 0.0670\n",
            "Val loss: 0.1951\n",
            "⚠️ Val loss worse than best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2070/2070 [11:08<00:00,  3.10it/s]\n",
            "100%|██████████| 518/518 [01:25<00:00,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/5\n",
            "Train loss: 0.0494\n",
            "Val loss: 0.0623\n",
            "⚠️ Val loss worse than best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}