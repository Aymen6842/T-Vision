{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6JDSCvJYoVF",
        "outputId": "fd3c26d6-ecc3-41c6-8329-06b36263881f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prêt dans /content/PHOTOCL !\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 2. Dézipper dans l'espace local de la machine virtuelle (C'est le secret de la vitesse)\n",
        "# Remplacez 'NomDuFichierTelecharge.zip' par le vrai nom s'il diffère après le téléchargement\n",
        "!unzip -q \"/content/drive/MyDrive/PHOTOCL.zip\" -d \"/content/PHOTOCL\"\n",
        "\n",
        "print(\"Dataset prêt dans /content/PHOTOCL !\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Configuration du Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Chemin vers votre dataset décompressé\n",
        "DATA_DIR = \"/content/PHOTOCL/dataset_original\"  # <--- Modifiez ceci avec votre chemin réel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS2ZZNj6vh_u",
        "outputId": "c26b54c3-f9b1-43fd-aabb-2acdbe480019"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PhotoCLBinaryDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Définition des classes binaires\n",
        "        # Photo = 1, Autres = 0\n",
        "        self.class_mapping = {\n",
        "            'Photo': 1,\n",
        "            'Painting': 0,\n",
        "            'Schematics': 0,\n",
        "            'Sketch': 0,\n",
        "            'Text': 0\n",
        "        }\n",
        "\n",
        "        # Parcours des dossiers\n",
        "        for class_name, label in self.class_mapping.items():\n",
        "            class_path = os.path.join(root_dir, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                continue\n",
        "\n",
        "            files = [os.path.join(class_path, f) for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "            self.image_paths.extend(files)\n",
        "            self.labels.extend([label] * len(files))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Chargement image (RGB)\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "        except:\n",
        "            # Gestion basique d'erreur : retourne une image noire si fichier corrompu\n",
        "            image = Image.new('RGB', (224, 224))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# 1. Définir les transformations spécifiques au ViT\n",
        "# ViT attend une normalisation ImageNet spécifique\n",
        "vit_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ViT patch size requires fixed input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 2. Charger le dataset complet\n",
        "full_dataset = PhotoCLBinaryDataset(DATA_DIR, transform=vit_transforms)\n",
        "\n",
        "# 3. Stratified Split (80% Train, 20% Val)\n",
        "# On utilise les labels pour s'assurer que la répartition 0/1 est la même dans train et val\n",
        "train_idx, val_idx = train_test_split(\n",
        "    list(range(len(full_dataset))),\n",
        "    test_size=0.2,\n",
        "    stratify=full_dataset.labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = Subset(full_dataset, train_idx)\n",
        "val_dataset = Subset(full_dataset, val_idx)\n",
        "\n",
        "# 4. DataLoaders\n",
        "BATCH_SIZE = 32 # Ajustez selon votre VRAM (16 ou 32 pour ViT)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6HsatJOvrS1",
        "outputId": "4ca9198a-2f0a-4f03-f45d-bf894082c51d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 33119, Val size: 8280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vit_model(num_classes=2):\n",
        "    print(\"Loading Pretrained ViT-B/16...\")\n",
        "    # Chargement des poids par défaut (ImageNet)\n",
        "    weights = models.ViT_B_16_Weights.DEFAULT\n",
        "    model = models.vit_b_16(weights=weights)\n",
        "\n",
        "    # Freeze des couches de base (Feature Extractor)\n",
        "    # Cela permet d'entraîner plus vite et évite l'overfitting sur un petit dataset\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Remplacement de la tête de classification (The \"heads\" block in torchvision ViT)\n",
        "    # Input dim of ViT-B/16 head is 768\n",
        "    model.heads = nn.Sequential(\n",
        "        nn.Linear(768, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, num_classes) # Sortie : 2 classes (Photo vs Autre)\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_vit_model().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Keavlumvxb7",
        "outputId": "ae86efbe-8880-4990-fb9d-b1792e14f804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Pretrained ViT-B/16...\n",
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 330M/330M [00:02<00:00, 165MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# On optimise seulement les paramètres de la nouvelle tête (heads)\n",
        "optimizer = optim.AdamW(model.heads.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "num_epochs = 5  # ViT converge vite en transfer learning\n",
        "history = {'train_loss': [], 'val_acc': []}\n",
        "print(\"Starting training...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # --- Training Phase ---\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Wrap train_loader with tqdm\n",
        "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", unit=\"batch\")\n",
        "\n",
        "    for inputs, labels in train_bar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Update progress bar with current batch loss\n",
        "        train_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    history['train_loss'].append(avg_loss)\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Wrap val_loader with tqdm\n",
        "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", unit=\"batch\", leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Optional: show rolling accuracy in val bar\n",
        "            val_bar.set_postfix(acc=f\"{(100 * correct / total):.2f}%\")\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    print(f\"Summary Epoch {epoch+1}: Loss: {avg_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J1SgtGwwQ5-",
        "outputId": "751db3d7-75c1-4bfb-de8e-468d40e9be62"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 [Train]: 100%|██████████| 1035/1035 [08:24<00:00,  2.05batch/s, loss=0.00311]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary Epoch 1: Loss: 0.0450, Val Accuracy: 98.91%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5 [Train]: 100%|██████████| 1035/1035 [08:23<00:00,  2.06batch/s, loss=0.000802]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary Epoch 2: Loss: 0.0179, Val Accuracy: 99.01%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5 [Train]: 100%|██████████| 1035/1035 [08:18<00:00,  2.07batch/s, loss=0.0247]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary Epoch 3: Loss: 0.0087, Val Accuracy: 99.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5 [Train]: 100%|██████████| 1035/1035 [08:20<00:00,  2.07batch/s, loss=5.77e-7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Epoch 4: Loss: 0.0065, Val Accuracy: 99.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5 [Train]: 100%|██████████| 1035/1035 [08:20<00:00,  2.07batch/s, loss=9.19e-7]\n",
            "                                                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Epoch 5: Loss: 0.0068, Val Accuracy: 99.17%\n",
            "Training finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calcul des métriques\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted') # Weighted pour gérer le déséquilibre si présent\n",
        "\n",
        "    print(f\"Final Accuracy: {acc:.4f}\")\n",
        "    print(f\"Final F1-Score: {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    # Target names: 0 = Autres, 1 = Photo\n",
        "    print(classification_report(y_true, y_pred, target_names=['Others', 'Photo']))\n",
        "\n",
        "    return y_true, y_pred\n",
        "\n",
        "# Lancer l'évaluation finale\n",
        "true_labels, predictions = evaluate_model(model, val_loader)\n",
        "\n",
        "# Sauvegarder le modèle pour la Phase 2\n",
        "torch.save(model.state_dict(), \"vit_photocl_classifier.pth\")\n",
        "print(\"Modèle sauvegardé : vit_photocl_classifier.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "HAfI9GPo9pfO",
        "outputId": "2564ae97-12ce-4c94-cfd3-4a69f9516c6c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3450961780.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Lancer l'évaluation finale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Sauvegarder le modèle pour la Phase 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_resnet_model(num_classes=2):\n",
        "    print(\"Loading Pretrained ResNet-50...\")\n",
        "    # Chargement des poids par défaut\n",
        "    weights = models.ResNet50_Weights.DEFAULT\n",
        "    model = models.resnet50(weights=weights)\n",
        "\n",
        "    # Freeze des couches de base\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Remplacement de la couche finale (FC)\n",
        "    # ResNet50 a 2048 features en entrée de la couche fully connected\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(in_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def get_efficientnet_model(num_classes=2):\n",
        "    print(\"Loading Pretrained EfficientNet-B0...\")\n",
        "    # Chargement des poids par défaut\n",
        "    weights = models.EfficientNet_B0_Weights.DEFAULT\n",
        "    model = models.efficientnet_b0(weights=weights)\n",
        "\n",
        "    # Freeze des couches de base\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Remplacement du classifier\n",
        "    # EfficientNet a une structure 'classifier' spécifique.\n",
        "    # La couche Dropout est souvent déjà présente (index 0), on change la Linear (index 1)\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "rB_tt7YCFBW-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELLULE RESNET ===\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "print(f\"{'='*20} Démarrage ResNet50 {'='*20}\")\n",
        "\n",
        "# 1. Définition du modèle ResNet50\n",
        "print(\"Chargement de ResNet50 pré-entraîné...\")\n",
        "weights = models.ResNet50_Weights.DEFAULT\n",
        "model_resnet = models.resnet50(weights=weights)\n",
        "\n",
        "# Freeze des couches (on ne touche pas aux features extraites)\n",
        "for param in model_resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Remplacement de la tête de classification (Fully Connected)\n",
        "# ResNet50 sort 2048 features avant la couche finale\n",
        "in_features = model_resnet.fc.in_features\n",
        "model_resnet.fc = nn.Sequential(\n",
        "    nn.Linear(in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 2)  # 2 classes : Photo vs Autre\n",
        ")\n",
        "\n",
        "model_resnet = model_resnet.to(device)\n",
        "\n",
        "# 2. Configuration Entraînement\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# On optimise uniquement la nouvelle tête (.fc)\n",
        "optimizer = optim.AdamW(model_resnet.fc.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "num_epochs = 5\n",
        "\n",
        "train_loss_history_resnet = []\n",
        "val_acc_history_resnet = []\n",
        "\n",
        "# 3. Boucle d'entraînement\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # --- Train ---\n",
        "    model_resnet.train()\n",
        "    running_loss = 0.0\n",
        "    train_bar = tqdm(train_loader, desc=f\"[ResNet] Epoch {epoch+1}/{num_epochs} [Train]\", leave=False, colour='green')\n",
        "\n",
        "    for inputs, labels in train_bar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_resnet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    train_loss_history_resnet.append(epoch_loss)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model_resnet.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_bar = tqdm(val_loader, desc=f\"[ResNet] Epoch {epoch+1}/{num_epochs} [Val  ]\", leave=False, colour='blue')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model_resnet(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            val_bar.set_postfix(acc=f\"{(100 * correct / total):.2f}%\")\n",
        "\n",
        "    epoch_acc = 100 * correct / total\n",
        "    val_acc_history_resnet.append(epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Loss: {epoch_loss:.4f} | Val Acc: {epoch_acc:.2f}% | Time: {time.time() - start_time:.1f}s\")\n",
        "\n",
        "# 4. Sauvegarde et Évaluation Rapide\n",
        "torch.save(model_resnet.state_dict(), \"resnet_photocl.pth\")\n",
        "print(\"\\nModèle sauvegardé : resnet_photocl.pth\")\n",
        "\n",
        "print(\"Évaluation finale ResNet...\")\n",
        "evaluate_model(model_resnet, val_loader)\n",
        "\n",
        "# Libérer la mémoire\n",
        "del model_resnet\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzqV-hCMHJgp",
        "outputId": "8569b106-97d2-44ea-f358-d9717fb5e652"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Démarrage ResNet50 ====================\n",
            "Chargement de ResNet50 pré-entraîné...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 0.0708 | Val Acc: 98.70% | Time: 484.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Loss: 0.0452 | Val Acc: 98.57% | Time: 478.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Loss: 0.0349 | Val Acc: 98.88% | Time: 477.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | Loss: 0.0288 | Val Acc: 98.79% | Time: 475.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | Loss: 0.0258 | Val Acc: 99.00% | Time: 476.9s\n",
            "\n",
            "Modèle sauvegardé : resnet_photocl.pth\n",
            "Évaluation finale ResNet...\n",
            "Final Accuracy: 0.9900\n",
            "Final F1-Score: 0.9900\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Others       0.99      0.99      0.99      6281\n",
            "       Photo       0.98      0.98      0.98      1999\n",
            "\n",
            "    accuracy                           0.99      8280\n",
            "   macro avg       0.99      0.99      0.99      8280\n",
            "weighted avg       0.99      0.99      0.99      8280\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELLULE EFFICIENTNET ===\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "print(f\"{'='*20} Démarrage EfficientNet-B0 {'='*20}\")\n",
        "\n",
        "# 1. Définition du modèle EfficientNet\n",
        "print(\"Chargement de EfficientNet-B0 pré-entraîné...\")\n",
        "weights = models.EfficientNet_B0_Weights.DEFAULT\n",
        "model_eff = models.efficientnet_b0(weights=weights)\n",
        "\n",
        "# Freeze des couches\n",
        "for param in model_eff.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Remplacement de la tête de classification\n",
        "# EfficientNet a un bloc 'classifier'. Index 1 est la couche linéaire.\n",
        "in_features = model_eff.classifier[1].in_features\n",
        "model_eff.classifier[1] = nn.Linear(in_features, 2) # 2 classes\n",
        "\n",
        "model_eff = model_eff.to(device)\n",
        "\n",
        "# 2. Configuration Entraînement\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# On optimise uniquement le classifier\n",
        "optimizer = optim.AdamW(model_eff.classifier.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "num_epochs = 5\n",
        "\n",
        "train_loss_history_eff = []\n",
        "val_acc_history_eff = []\n",
        "\n",
        "# 3. Boucle d'entraînement\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # --- Train ---\n",
        "    model_eff.train()\n",
        "    running_loss = 0.0\n",
        "    train_bar = tqdm(train_loader, desc=f\"[EfficientNet] Epoch {epoch+1}/{num_epochs} [Train]\", leave=False, colour='magenta')\n",
        "\n",
        "    for inputs, labels in train_bar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_eff(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    train_loss_history_eff.append(epoch_loss)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model_eff.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_bar = tqdm(val_loader, desc=f\"[EfficientNet] Epoch {epoch+1}/{num_epochs} [Val  ]\", leave=False, colour='cyan')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model_eff(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            val_bar.set_postfix(acc=f\"{(100 * correct / total):.2f}%\")\n",
        "\n",
        "    epoch_acc = 100 * correct / total\n",
        "    val_acc_history_eff.append(epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Loss: {epoch_loss:.4f} | Val Acc: {epoch_acc:.2f}% | Time: {time.time() - start_time:.1f}s\")\n",
        "\n",
        "# 4. Sauvegarde et Évaluation Rapide\n",
        "torch.save(model_eff.state_dict(), \"efficientnet_photocl.pth\")\n",
        "print(\"\\nModèle sauvegardé : efficientnet_photocl.pth\")\n",
        "\n",
        "print(\"Évaluation finale EfficientNet...\")\n",
        "evaluate_model(model_eff, val_loader)\n",
        "\n",
        "# Libérer la mémoire\n",
        "del model_eff\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnrJN6IBJuJc",
        "outputId": "875c85b1-4d01-4064-aaca-ddb5fef63e99"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Démarrage EfficientNet-B0 ====================\n",
            "Chargement de EfficientNet-B0 pré-entraîné...\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 153MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 0.1802 | Val Acc: 96.17% | Time: 449.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Loss: 0.1329 | Val Acc: 96.64% | Time: 442.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Loss: 0.1299 | Val Acc: 96.76% | Time: 445.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | Loss: 0.1234 | Val Acc: 96.86% | Time: 453.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | Loss: 0.1173 | Val Acc: 97.03% | Time: 442.2s\n",
            "\n",
            "Modèle sauvegardé : efficientnet_photocl.pth\n",
            "Évaluation finale EfficientNet...\n",
            "Final Accuracy: 0.9703\n",
            "Final F1-Score: 0.9703\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Others       0.98      0.98      0.98      6281\n",
            "       Photo       0.94      0.94      0.94      1999\n",
            "\n",
            "    accuracy                           0.97      8280\n",
            "   macro avg       0.96      0.96      0.96      8280\n",
            "weighted avg       0.97      0.97      0.97      8280\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRdtttQNcj4V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}